{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework (deadline 18.11.2022 13:44:59)\n",
    "Write solutions for the homework exercises in this notebook. Once the work is done download the notebook file (`File > Download .ipynb`) rename it properly so it follows a template `HW1_<SURNAME>_<NAME>.ipynb` and send the file to me. My email address is as follows: \n",
    "\n",
    "* <m.biesaga@uw.edu.pl>\n",
    "\n",
    "Remember that you can contact me via email if you have any problems. Moreover, you can also visit me in the ISS on the fourth floor (room 415). Usually, I am there from 11ish but please let me know in advance if you are coming because I might be busy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (5 points)\n",
    "\n",
    "Read about the `pageviews` method (`prop=pageviews`) in the `query endpoint` ([docpage](https://en.wikipedia.org/w/api.php?action=help&modules=query%2Bpageviews)). Use this method to extract page views data for the pages from the exercise we did during the class (if you want you can sample 10 new pages with the `list=random` method) for the last 60 days. The results will be broken down by single days, so you have to aggregate the results (sum) so they give the total page views count for the entire period of 60 days. Remember that to select pages by page ids you pass `pageids=<id 1>|<id 2>|...|<id n>`. We did a very similar thing when we extracted article content through the `cirrusdoc` method in the Wikipedia API. Your final output should be a `dict` object that maps page ids to pageviews (total number of pageviews over 60 days). It should look something like this:\n",
    "\n",
    "```python\n",
    "results = {\n",
    "    # page_id: pageviews\n",
    "    153253: 10204,\n",
    "    423423: 101,\n",
    "    11012:  12,\n",
    "    42435:  546,\n",
    "    # and so on\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import module requests\n",
    "import requests as rq\n",
    "\n",
    "## Some page ids\n",
    "page_ids = [\n",
    "    19969580,\n",
    "    39982842,\n",
    "    25699035,\n",
    "    52642931,\n",
    "    53055349,\n",
    "    24133565,\n",
    "    1164662,\n",
    "    40656459,\n",
    "    12533026,\n",
    "    47110862\n",
    "]\n",
    "\n",
    "## API URL\n",
    "BASE_URL = 'https://en.wikipedia.org/w/api.php'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taks 2 (5 + 2 points)\n",
    "In this task, you can score either 5 points or 7. The only difference is in the pages you will download. To score 5 points you just need to download the content of 20 random pages from Wikipedia (please review the [N1](https://github.com/MikoBie/ids/blob/main/notebooks/N1.ipynb) in which we downloaded the content of 10 random pages). To have the chance to score 7 points you need to download the content of 10 pages that have in the title `Olivia` and 10 pages that have `Noah` (those are the most popular names in the UK in 2021). \n",
    "\n",
    "**Hint for 7 points**: you might find this [`pssearch`](https://en.wikipedia.org/w/api.php?action=help&modules=query%2Bprefixsearch) method interesting.\n",
    "\n",
    "When you have the content of these 20 articles for each one of them compute a distribution of the following possessive pronouns: `her`, `his`, and `their`. In other words, you should end up with the list looking more or less like this one (but has 20 elements):\n",
    "\n",
    "```python\n",
    "[{'his': 79, 'her': 212, 'their': 14},\n",
    " {'his': 36, 'her': 147, 'their': 20},\n",
    " {'his': 17, 'her': 80, 'their': 6},\n",
    " {'his': 8, 'her': 80, 'their': 9},\n",
    " {'his': 14, 'her': 66, 'their': 2},\n",
    " {'his': 12, 'her': 188, 'their': 16},\n",
    " {'his': 3, 'her': 156, 'their': 13},\n",
    " {'his': 33, 'her': 126, 'their': 33},\n",
    " {'his': 10, 'her': 113, 'their': 8},\n",
    " {'his': 21, 'her': 4, 'their': 33}]\n",
    "```\n",
    "**Hint**: Remember that sometimes in articles pronouns starts with the capital letter (ignore the cases like `hers` and `theirs`). Moreover, review the [notebook number 5](https://github.com/MikoBie/ppss/blob/main/notebooks/N5.ipynb) about the lists from May 19th, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import module requests\n",
    "import requests as rq\n",
    "URL = 'https://en.wikipedia.org/w/api.php'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
