{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework (deadline 18.11.2022 13:44:59)\n",
    "Write solutions for the homework exercises in this notebook. Once the work is done download the notebook file (`File > Download .ipynb`) rename it properly so it follows a template `HW5_<SURNAME>_<NAME>.ipynb` and send the file to me. Please also attach all files you will be asked to produce in this homework. My email address is as follows: \n",
    "\n",
    "* <m.biesaga@uw.edu.pl>\n",
    "\n",
    "Remember that you can contact me via email if you have any problems. Moreover, you can also visit me in the ISS on the fourth floor (room 415). Usually, I am there from 11ish but please let me know in advance if you are coming because I might be busy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 (5 points)\n",
    "\n",
    "Read about the `pageviews` method (`prop=pageviews`) in the `query endpoint` ([docpage](https://en.wikipedia.org/w/api.php?action=help&modules=query%2Bpageviews)). Use this method to extract page views data for the pages from the previous exercise (if you want you can sample 10 new pages with the `list=random` method) for the last 60 days. The results will be broken down by single days, so you have to aggregate the results (sum) so they give the total page views count for the entire period of 60 days. Remember that to select pages by page ids you pass `pageids=<id 1>|<id 2>|...|<id n>`. We did a very similar thing when we extracted article content through the `cirrusdoc` method in the Wikipedia API in the previous part of this notebook. Your final output should be a `dict` object that maps page ids to pageviews (total number of pageviews over 60 days). It should look something like this:\n",
    "\n",
    "```python\n",
    "results = {\n",
    "    # page_id: pageviews\n",
    "    153253: 10204,\n",
    "    423423: 101,\n",
    "    11012:  12,\n",
    "    42435:  546,\n",
    "    # and so on\n",
    "}\n",
    "```\n",
    "\n",
    "If you want you can sample 10 pages yourself. Otherwise, you may use the following list of page ids that we prepared for you. Sampling pages yourself will give you extra credit (but it is possible to get maximum points without it as well)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import module requests\n",
    "import requests\n",
    "\n",
    "## Some page ids\n",
    "page_ids = [\n",
    "    19969580,\n",
    "    39982842,\n",
    "    25699035,\n",
    "    52642931,\n",
    "    53055349,\n",
    "    24133565,\n",
    "    1164662,\n",
    "    40656459,\n",
    "    12533026,\n",
    "    47110862\n",
    "]\n",
    "\n",
    "## API URL\n",
    "BASE_URL = 'https://en.wikipedia.org/w/api.php'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'action': 'query',\n",
    "    'prop': 'pageviews',\n",
    "    'pageids': '|'.join(str(pid) for pid in page_ids),\n",
    "    'pvidays': 60,\n",
    "    'format': 'json'\n",
    "}\n",
    "response = requests.get(BASE_URL, params=params)\n",
    "response\n",
    "\n",
    "\n",
    "data = response.json()['query']['pages']\n",
    "## My friends solution\n",
    "PVS = { v['title']: sum(filter(None, v.get('pageviews', {}).values())) for v in data.values() }\n",
    "## My solutions\n",
    "PVM = { v['title'] : sum([ item for item in v['pageviews'].values() if item is not None ]) for v in data.values() }\n",
    "PVS == PVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taks 2 (5 + 2 points)\n",
    "In this task, you can score either 5 points or 7. The only difference is in the pages you will download. To score 5 points you just need to download the content of 20 random pages from Wikipedia (please review the [N1](https://github.com/MikoBie/ids/blob/main/notebooks/N1.ipynb) in which we downloaded the content of 10 random pages). To have the chance to score 7 points you need to download the content of 10 pages that have in the title `Olivia` and 10 pages that have `Noah` (those are the most popular names in the UK in 2021). \n",
    "\n",
    "**Hint for 7 points**: you might find this [`pssearch`](https://en.wikipedia.org/w/api.php?action=help&modules=query%2Bprefixsearch) method interesting.\n",
    "\n",
    "When you have the content of these 20 articles for each one of them compute a distribution of the following possessive pronouns: `her`, `his`, and `their`. In other words, you should end up with the list looking more or less like this one:\n",
    "\n",
    "```python\n",
    "[{'his': 79, 'her': 212, 'their': 14},\n",
    " {'his': 36, 'her': 147, 'their': 20},\n",
    " {'his': 17, 'her': 80, 'their': 6},\n",
    " {'his': 8, 'her': 80, 'their': 9},\n",
    " {'his': 14, 'her': 66, 'their': 2},\n",
    " {'his': 12, 'her': 188, 'their': 16},\n",
    " {'his': 3, 'her': 156, 'their': 13},\n",
    " {'his': 33, 'her': 126, 'their': 33},\n",
    " {'his': 10, 'her': 113, 'their': 8},\n",
    " {'his': 21, 'her': 4, 'their': 33}]\n",
    "```\n",
    "**Hint**: Remember that sometimes in articles pronouns starts with the capital letter (ignore the cases like `hers` and `theirs`). Moreover, review the [notebook number 5](https://github.com/MikoBie/ppss/blob/main/notebooks/N5.ipynb) about the lists from May 19th, 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import module requests\n",
    "import requests\n",
    "BASE_URL = 'https://en.wikipedia.org/w/api.php'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "URL = 'https://en.wikipedia.org/w/api.php'\n",
    "payload = { 'action' : 'query',\n",
    "            'list' : 'prefixsearch',\n",
    "            'pssearch' : 'Anne',\n",
    "            'format' : 'json',\n",
    "            'pslimit' : 11\n",
    "}\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rq.get(URL, payload)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [ item['pageid'] for item in data['query']['prefixsearch'][1:] ]\n",
    "names = [ item['title'] for item in data['query']['prefixsearch'][1:] ]\n",
    "ids_str = '|'.join( str(item) for item in ids )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = { 'action' : 'query',\n",
    "            'prop' : 'cirrusdoc',\n",
    "            'pageids' : ids_str,\n",
    "            'format' : 'json'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = rq.get(URL, payload)\n",
    "data = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [ p['cirrusdoc'][0]['source']['text'] for p in data['query']['pages'].values() ]\n",
    "named_articles = zip(names, articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men_pronouns = []\n",
    "for k, item in named_articles:\n",
    "    pronouns = { 'his' : 0,\n",
    "             'her' : 0,\n",
    "             'their' : 0\n",
    "             }\n",
    "    l = item.lower().split()\n",
    "    pronouns['his'] = l.count('his')    \n",
    "    pronouns['her'] = l.count('her')    \n",
    "    pronouns['their'] = l.count('their')    \n",
    "    men_pronouns.append({k : pronouns })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "men_pronouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('ids')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f6b087e3237558552441618582c1cfff7dc162872ae65c00a668bb71df085d3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
