{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MediaCloud\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"png/mediacloud.png\" /></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is MediaCloud?\n",
    "\n",
    "[Media Cloud](https://www.mediacloud.org) is an open-source media research project, enabling the study of news and information flow globally. The project is administered as a consortium collaboration between the Media Ecosystems Analysis Group, the University of Massachusetts Amherst, and Northeastern University. It was originally incubated at Harvard University and the Massachusetts Institute of Technology.\n",
    "\n",
    "In simple terms, it is a platform that **collects** and analyzes news articles from various sources, allowing researchers to study media trends, narratives, and the spread of information over time. It provides tools for data collection, text analysis, and visualization, making it a valuable resource for journalists, academics, and anyone interested in understanding the dynamics of media coverage.\n",
    "\n",
    "However, Media Cloud is **not** a repository of news articles. Instead, it provides **metadata** and **text analysis** of articles collected from various sources. The actual articles themselves are not stored within Media Cloud; rather, the platform focuses on analyzing the content and patterns within the media landscape.\n",
    "\n",
    "## Media Cloud API\n",
    "\n",
    "You can interact with Media Cloud either through their web interface or programmatically using their API. The API allows you to query the Media Cloud database, retrieve metadata about articles, and perform various analyses. In general, there are two main components of the Media Cloud API:\n",
    "\n",
    "1. Media Cloud API: Search Against Media Cloud's new Online News Archive, with access to 200 million+ stories and growing every day. Search against hundreds of sources and collections we have developed.\n",
    "2. Wayback Machine: Search against the Wayback Machineâ€™s database through an API we developed to be able to search against the large number of sources and collections we have developed. Search is against the title text.\n",
    "\n",
    "In this notebook, we will focus on the Media Cloud API. However, first, we will start by briefly exploring the web interface.\n",
    "\n",
    "## Setting Up an Account\n",
    "\n",
    "To use the Media Cloud API, you need to set up an account and obtain an API key. Follow these steps:\n",
    "\n",
    "1. Visit the [Media Cloud website](https://www.mediacloud.org) and sign up for an account.\n",
    "2. Once you are logged in, navigate to your profile settings and press Request API Access (see the image below).\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"png/mediacloud_api.png\" /></div>\n",
    "\n",
    "3. After requesting access, you will receive an email with a link to confirm your API access. Click the link to confirm.\n",
    "4. Once confirmed, you can find your API key in your profile settings (see the image below).\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"png/mediacloud_api_key.png\" /></div>\n",
    "\n",
    "In the picture above, I hid some information because those are the credentials (API Key) you will use to tell Media Cloud who you are. You should never share them with anyone, even your spouse or a firefighter! That is because they serve to identify you. If someone maluses them, it will be on you. \n",
    "\n",
    "## Storing your credentials\n",
    "\n",
    "There are multiple ways to store your credentials and passwords safely. We don't want them to be corrupted, right? However, it is one thing to store them [safely](https://youtu.be/MnjQV--o1-0?si=hIlgl9sCyt4JhVUd) and the other to have [strong passwords](https://youtu.be/mQ36sUT77qI?si=hxRw4O4UxKM_WUPy). We all know that we should use strong passwords, but do we really know why? The picture below shows how fast one can crack your password depending on its complexity.\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"png/password_table_2023.jpg\"/></div>\n",
    "\n",
    "Anyhow, the lesson we should take from the graph above is twofold:\n",
    "\n",
    "1. Use strong passwords.\n",
    "2. Use password managers to propose strong passwords and store them.\n",
    "\n",
    "If, for any reason, you are still reluctant to trust password managers, at least create complex passwords by mixing nonsense words (it is the only place where making spelling errors helps) and special characters, for example:\n",
    "\n",
    ">`$eating#keyborads-1ncreases_staminA`\n",
    "\n",
    "In our case, we have already generated passwords and credentials that look pretty strong. How are we going to store them?\n",
    "\n",
    "### Environmental variables\n",
    "\n",
    "As you probably rightly suspect, in our case, we will need our credentials to connect to the API. We don't really want to store them in the notebook because we want to be able to share the notebook (you want to share it with me, and I want to share it with you). We don't want to copy and paste them every time we want to use the notebook, cause it would be very inefficient. Also, it will be quite easy to forget about it. What are we going to do then?\n",
    "\n",
    "We are going to use something called environmental variables. In other words, we are going to define some variables either on our computer or in the Colab that will be stored there. In the Notebook, we will just retrieve them by their names. For this purpose, we need to press the key on the left-hand side tab. We need to define the 5 variables:\n",
    "\n",
    "* `API_KEY` -- this is our API Key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load module\n",
    "from google.colab import userdata\n",
    "\n",
    "## Retrive our environmental variables and assing them to names.\n",
    "API_KEY = userdata.get(\"API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Media Cloud Module\n",
    "\n",
    "So, when we finally do have our credentials in the Notebook, what are we going to do next? We need to pass it somehow through a request to the Media Cloud API, right? Intuitively, we would do it through a payload and `request` module, right? Yes, this is a good intuition, but fortunately, we don't really have to do it this way. That is because most social media have so-called wrappers. Those are modules that allow us to connect to the API and send requests. We could still do it through our web browser, but the URL would be much more complicated.\n",
    "\n",
    "That is why, in the case of Media Cloud, we will use the module. It will serve us to connect and get data from Media Cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Install mediacloud module\n",
    "!pip install mediacloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import modules\n",
    "import mediacloud.api\n",
    "import datetime as dt\n",
    "\n",
    "## Connect to Media Cloud\n",
    "search_api = mediacloud.api.SearchApi(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a bit underwhelming because nothing was printed. To check whether everything worked well, we can just execute the following. It will return information about our user account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Print user's information\n",
    "search_api.user_profile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important information from this dictionary is about the quota. This tells us how many requests we made and how much we have left this week. \n",
    "\n",
    "## Counts\n",
    "\n",
    "Anyway, once we have established a connection to Media Cloud, let's now try to get some data. We will start with searching for the number of articles that contained the name of sensational [Caitlin Clark](https://en.wikipedia.org/wiki/Caitlin_Clark) -- number 1 in the 2024 WNBA Draft. There are multiple ways in which we can construct the query string. They are described in the [documentation](https://www.mediacloud.org/documentation/query-guide). Here, we will use the simplest -- we will just type her name and surname in quotation marks, which will guarantee that we hit only articles with the `\"Caitlin Clark\"` string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The method search_api.story_count() returns a dictionary with the number of stories that matched the query.\n",
    "clark_all = search_api.story_count(\n",
    "    query=\"'Caitlin Clark'\", start_date=dt.date(2025, 1, 1), end_date=dt.date.today()\n",
    ")\n",
    "clark_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is more, we can specify a resource to search in. For example, the New York Times. However, to do that, we need to know its media ID. We can find it through the Media Cloud web interface or through a different API endpoint. However, let's, for now, assume we will use the web interface for this. At the end of the notebook, we will come back to investigating available sources through the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can add a list of sources.\n",
    "clark_all_ny = search_api.story_count(\n",
    "    \"'Caitlin Clark'\",\n",
    "    start_date=dt.date(2025, 1, 1),\n",
    "    end_date=dt.date.today(),\n",
    "    source_ids=[1],\n",
    ")\n",
    "clark_all_ny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, most of the time, the count sum for the whole search is kind of useless. Probably, it would be much better to aggregate daily. Say no more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data aggregated daily.\n",
    "clark_ny = search_api.story_count_over_time(\n",
    "    \"'Caitlin Clark'\",\n",
    "    start_date=dt.date(2025, 1, 1),\n",
    "    end_date=dt.date.today(),\n",
    "    source_ids=[1],\n",
    ")\n",
    "clark_ny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Find a day this year when Caitlin Clark was mentioned the most inThe  New York Times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can also search through a collection of sources. Media Cloud has a set of collections of sources that are specific to a given country. Similarly to the source id, we need to know the id of a given collection. There are two ways of learning it, either through the web interface or through the API. Again, we will talk about the API pathway later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of getting data from a collection of sources.\n",
    "clark_collection = search_api.story_count_over_time(\n",
    "    \"'Caitlin Clark'\",\n",
    "    start_date=dt.date(2025, 1, 1),\n",
    "    end_date=dt.date.today(),\n",
    "    collection_ids=[34412234],\n",
    ")\n",
    "clark_collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see how it changed over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import functions for plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "## Prepare data.\n",
    "x = [item[\"date\"] for item in clark_ny]\n",
    "y_count = [item[\"count\"] for item in clark_ny]\n",
    "y_ratio = [item[\"ratio\"] for item in clark_ny]\n",
    "\n",
    "## Define plot.\n",
    "fig, axs = plt.subplots(figsize=(9, 5), nrows=2)\n",
    "axs[0].plot(x, y_count, color=\"#C8102E\")\n",
    "axs[0].set_ylabel(\"Count\")\n",
    "axs[1].plot(x, y_ratio, color=\"#041E42\")\n",
    "axs[1].set_ylabel(\"Ratio\")\n",
    "## Edit xticks so they show the names of the months only.\n",
    "for ax in axs:\n",
    "    ax.xaxis.set_major_locator(mdates.MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%b\"))\n",
    "## Add title.\n",
    "plt.suptitle(\n",
    "    f\"Dynamics of the number articles on Caitlin Clark in NY Times in 2025\\n(N = {clark_all_ny['relevant']})\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can search for the sources with the most articles with a given phrase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clark_sources = search_api.sources(\n",
    "    \"'Caitlin Clark'\", start_date=dt.date(2025, 1, 1), end_date=dt.date.today()\n",
    ")\n",
    "clark_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Words\n",
    "\n",
    "The most analytical thing we can extract from the Media Cloud is the most popular words that were used in the articles on the given topic. Unfortunately, this is only estimated on the sample of a maximum $5000$ articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get 100 top words from the articles.\n",
    "clark_words = search_api.words(\n",
    "    \"'Caitlin Clark'\",\n",
    "    start_date=dt.date(2025, 1, 1),\n",
    "    end_date=dt.date.today(),\n",
    "    collection_ids=[34412234],\n",
    ")\n",
    "clark_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Create a dictionary in which keys will represent terms and values will be term ratios. Filter out words: `\"Caitlin\"` and `\"Clark\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE\n",
    "words = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now draw a word cloud. This is one of the most useless graphs (I think it is even worse than a pie chart). However, sometimes it looks nice. And people do use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import modules\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## Define the plot.\n",
    "wordcloud = WordCloud(\n",
    "    width=800, height=400, background_color=\"white\"\n",
    ").generate_from_frequencies(words)\n",
    "\n",
    "## Define the size of the plot.\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Caitlin Clark Word Cloud\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lists\n",
    "\n",
    "Finally, what is probably the most interesting and useful are lists of metadata. Using Media Cloud, you can find metadata about the articles on a given topic. In simple terms, you can get the titles of all articles on `\"Caitlin Clark\"` from 2025. The simplest way of getting the list of metadata is by using the `search_api.story_sample()` method. However, as the name suggests, it can only provide us with a sample of metadata. The maximum limit is $1250$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's get the list of metadata\n",
    "clark_meta_sample = search_api.story_sample(\n",
    "    \"'Caitlin Clark'\",\n",
    "    start_date=dt.date(2025, 1, 1),\n",
    "    end_date=dt.date.today(),\n",
    "    limit=500,\n",
    "    collection_ids=[34412234],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's see the example of the result\n",
    "clark_meta_sample[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a method that returns metadata for all the articles. However, it takes much longer. It gets 1000 articles every 30 seconds. That is because the API will send us all the articles in batches of 1000. Moreover, there is a rate limit at this endpoint. It means that we can send only 2 requests per minute to it. But how to do it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import module to control time\n",
    "import time\n",
    "\n",
    "## Output list\n",
    "clark_meta_all = []\n",
    "\n",
    "## The id of the next batch of data\n",
    "pagination_token = None\n",
    "\n",
    "## Control variable\n",
    "more_stories = True\n",
    "\n",
    "## How much data is there to collect\n",
    "clark_all = search_api.story_count(\n",
    "    \"'Caitlin Clark'\",\n",
    "    start_date=dt.date(2025, 1, 1),\n",
    "    end_date=dt.date.today(),\n",
    "    collection_ids=[34412234],\n",
    ")\n",
    "\n",
    "while more_stories:\n",
    "    ## Estimate time left\n",
    "    estimated_time = 31 * (clark_all[\"relevant\"] - len(clark_meta_all)) / 1000\n",
    "\n",
    "    ## Print how much data was collected\n",
    "    print(\n",
    "        f\"Collected {len(clark_meta_all)} out of {clark_all[\"relevant\"]}. Around {estimated_time} seconds left.\"\n",
    "    )\n",
    "\n",
    "    ## Wait to make another request\n",
    "    time.sleep(31)\n",
    "\n",
    "    ## search_api.story_list() returns a two elements long tuple. The\n",
    "    ## first element is a list of dictionaries. The second element is\n",
    "    ## the id of the next batch of data\n",
    "    page, pagination_token = search_api.story_list(\n",
    "        \"'Caitlin Clark'\",\n",
    "        start_date=dt.date(2025, 1, 1),\n",
    "        end_date=dt.date.today(),\n",
    "        collection_ids=[34412234],\n",
    "        pagination_token=pagination_token,\n",
    "    )\n",
    "\n",
    "    ## Update the list\n",
    "    clark_meta_all += page\n",
    "\n",
    "    ## Update the control variable\n",
    "    more_stories = pagination_token is not None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Find all the sources that are overrepresented in the sample of 500 articles compared to the sample of 1250 articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
